---
title: "PREDICT_2019"
author: "Ethan Greig"
date: "11/17/2018"
output: pdf_document
---

```{r}
library(knitr)
source(purl('import_and_generate_series.Rmd', output = tempfile()))
# Note that only data from 2008-2017 is imported here. 2018 data is kept as a holdout set
```

## Define Some Metrics
```{r}
logLoss <- function(pred, actual){
  -mean(log(abs(1-actual-pred)))
}

acc <- function(pred, actual){
  wlpred <- round(pred, 0)
  correct <- wlpred==actual
  num_correct <- sum(correct, na.rm=TRUE)
  return(num_correct/length(correct))
}
```

## Cross-Validation for Logistic Regression Model
```{r}

cv_lr <- function(data, nfolds=10, nruns=1000, symm=FALSE) {
  set.seed(0)
  n <- nrow(data)
  results <- matrix(nrow=nruns, ncol=4)
  
  for (i in 1:nruns) {
    data_shuffled <- data[sample(n),]
    folds <- cut(seq(1,n),breaks=nfolds,labels=FALSE)
  
    log_loss <- NA
    accuracy <- NA
      
    for (j in 1:nfolds) {
      test_rows <- which(folds==j,arr.ind=TRUE)
      test_data <- data_shuffled[test_rows,]
      train_data <- data_shuffled[-test_rows,]
        
      if (symm==TRUE) {
        test_data$Home_Adv <- 1
        train_data$Home_Adv <- 1
        train_data_flip <- -train_data
        train_data_flip$Home_Won <- 1-train_data$Home_Won
        train_data <- rbind(train_data, train_data_flip)
      }
        
      fold_model <- glm(`Home_Won` ~ .,data=train_data, family=binomial(link='logit'))
      test_data$fold_prediction <- predict(fold_model, subset(test_data, select=-Home_Won), type='response')
    
      log_loss[j] <- logLoss(test_data$fold_prediction, test_data$Home_Won)
      accuracy[j] <- acc(test_data$fold_prediction, test_data$Home_Won)
    }
      
    results[i,] = c(mean(log_loss), sd(log_loss), mean(accuracy), sd(accuracy))
  }
  
  print(setNames(data.frame(t(colMeans(results))), c('LR Log Loss', 'Std. Dev.', 'LR Accuracy', 'Std. Dev.')))
}
```

## Logistic Regression Benchmark:
```{r}
# cv_lr(df)
# Log Loss: 0.81 (sd 0.25)
# Accuracy: 60% (sd 0.12)}
```

## Cross Validation for Random Forest (Regression) Model
```{r}
library(randomForest)
# tried: using Home_W%

cv_rf_reg <- function(data, nfolds=10, nruns=24, mtry=floor(ncol(df)/3), nodesize=5) {
  set.seed(0)
  n <- nrow(data)
  results <- matrix(nrow=nruns, ncol=4)
  
  for (i in 1:nruns) {
    data_shuffled <- data[sample(n),]
    folds <- cut(seq(1,n),breaks=nfolds,labels=FALSE)
      
    log_loss <- NA
    accuracy <- NA
      
    for (j in 1:nfolds) {
      test_rows <- which(folds==j,arr.ind=TRUE)
      test_data <- data_shuffled[test_rows,]
      train_data <- data_shuffled[-test_rows,]
  
      fold_model <- suppressWarnings(randomForest(`Home_Won` ~ .,data=train_data, ntree=4000, mtry=mtry, nodesize=nodesize))
      test_data$fold_prediction <- predict(fold_model, subset(test_data, select=-Home_Won), type='response')
        
      log_loss[j] <- logLoss(test_data$fold_prediction, test_data$Home_Won)
      accuracy[j] <- acc(test_data$fold_prediction, test_data$Home_Won)
    }
      
    results[i,] = c(mean(log_loss), sd(log_loss), mean(accuracy), sd(accuracy))
  }
  
  print(setNames(data.frame(t(colMeans(results))), c('RF Log Loss', 'Std. Dev.', 'RF Accuracy', 'Std. Dev.')))
}
```

## Random Forest (Regression) Benchmark:
```{r}
cv_rf_reg(df)
# Log Loss: 0.676 (sd 0.11)
# Accuracy: 62% (sd 0.13)
```


## Cross Validation for Random Forest (Classification) Model
```{r}
library(randomForest)
# tried: using Home_W%

cv_rf_class <- function(data, nfolds=10, nruns=24, mtry=floor(sqrt(ncol(df))), nodesize=1) {
  set.seed(0)
  n <- nrow(data)
  results <- matrix(nrow=nruns, ncol=4)
  
  for (i in 1:nruns) {
    data_shuffled <- data[sample(n),]
    folds <- cut(seq(1,n),breaks=nfolds,labels=FALSE)
      
    log_loss <- NA
    accuracy <- NA
      
    for (j in 1:nfolds) {
      test_rows <- which(folds==j,arr.ind=TRUE)
      test_data <- data_shuffled[test_rows,]
      train_data <- data_shuffled[-test_rows,]
      train_data$Home_Won <- as.factor(train_data$Home_Won)
  
      fold_model <- suppressWarnings(randomForest(`Home_Won` ~ .,data=train_data, ntree=4000))
      test_data$fold_prediction <- predict(fold_model, subset(test_data, select=-Home_Won), type='prob')[,2]
        
      log_loss[j] <- logLoss(test_data$fold_prediction, test_data$Home_Won)
      accuracy[j] <- acc(test_data$fold_prediction, test_data$Home_Won)
    }
      
    results[i,] = c(mean(log_loss), sd(log_loss), mean(accuracy), sd(accuracy))
  }
  
  print(setNames(data.frame(t(colMeans(results))), c('RF Log Loss', 'Std. Dev.', 'RF Accuracy', 'Std. Dev.')))
}
```

## Random Forest (Classification) Benchmark:
```{r}
cv_rf_class(df)
# Log Loss: 0.67 (sd 0.11)
# Accuracy: 62.5% (sd 0.12)
```