---
title: "PREDICT_2019"
author: "Ethan Greig"
date: "11/17/2018"
output: pdf_document
---

```{r}
library(knitr)
source(purl('import_and_generate_series.Rmd', output = tempfile()))
# Note that only data from 2008-2017 is imported here. 2018 data is kept as a holdout set
```

# Remove highly-correlated features
```{r}
corr <- cor(series[,c('Home_Won', dStats)])
corr_vars <- names(data.frame(corr))[which(corr>0.88 & corr<1, arr.ind = TRUE)[, "col"]]

# cor(series[,c('Home_Won', corr_vars)]) # Remove one feature from each highly-correlated pair
dStats <- dStats[!dStats%in%c('dCF._55', 'dCF.60_all', 'dCA._all', 'dBerg', 'dxGF.60_all', 'dSh._all')]
```

## Define Some Metrics
```{r}
logLoss <- function(pred, actual){
  -1*mean(log(pred[model.matrix(~ actual + 0) - pred > 0]))
}

acc <- function(pred, actual){
  wlpred <- round(pred, 0)
  correct <- wlpred==actual
  num_correct <- sum(correct, na.rm=TRUE)
  return(num_correct/length(correct))
}
```

## Cross-Validation
```{r}
library(randomForest)

df <- series[,c('Home_Won', dStats)]
df[,dStats] <- data.frame(scale(df[,dStats]))
df[,'Home_Won'] <- as.factor(df[,'Home_Won'])
# tried: using Home_W%, using symmetric df

cv <- function(data, model='log', nfolds=10, nruns=1, symm=FALSE) {
  set.seed(0)
  n <- nrow(data)
  results <- matrix(nrow=nruns, ncol=4)
  
  for (i in 1:nruns) {
    data_shuffled <- data[sample(n),]
    folds <- cut(seq(1,n),breaks=nfolds,labels=FALSE)
    
    log_loss <- NA
    accuracy <- NA
    
    for (j in 1:nfolds) {
    test_rows <- which(folds==j,arr.ind=TRUE)
    test_data <- data_shuffled[test_rows,]
    train_data <- data_shuffled[-test_rows,]
    
    if (symm==TRUE) {
      test_data$Home_Adv <- 1
      train_data$Home_Adv <- 1
      train_data_flip <- -train_data
      train_data_flip$Home_Won <- 1-train_data$Home_Won
      train_data <- rbind(train_data, train_data_flip)
    }
    
    if (model=='log') {
      df[,'Home_Won'] <- as.numeric(as.character(df[,'Home_Won']))
      fold_model <- suppressWarnings(glm(`Home_Won` ~ .,data=train_data, family=binomial(link='logit')))
      test_data$fold_prediction <- predict(fold_model, subset(test_data, select=-Home_Won), type='response')
    }
    else if (model=='rf') {
      df[,'Home_Won'] <- as.factor(df[,'Home_Won']) # rf classification requires target to be a factor
      fold_model <- suppressWarnings(randomForest(`Home_Won` ~ .,data=train_data, ntree=2000))
      test_data$fold_prediction <- predict(fold_model, subset(test_data, select=-Home_Won), type='prob')[,2]
      df[,'Home_Won'] <- as.numeric(as.character(df[,'Home_Won']))
    }
    
    log_loss[j] <- logLoss(test_data$fold_prediction, test_data$Home_Won)
    accuracy[j] <- acc(test_data$fold_prediction, test_data$Home_Won)
    }
    
  results[i,] = c(mean(log_loss), sd(log_loss), mean(accuracy), sd(accuracy))
  }

return(setNames(data.frame(t(colMeans(results))), c('Log Loss', 'sd', 'Accuracy', 'sd')))
}
```

## Using Default Parameters
```{r}
cv(df, nfolds=10, model='log', nruns=500) # 0.74 (sd 0.35) 60% (sd 0.12)
cv(df, nfolds=10, model='rf', nruns=16) # 0.59 (sd 0.13) 63% (0.12)
```

## Hyperparameter Tuning on RF model
```{r}
# Grid Search using randomForest's built in OOB error
ntree <- 3000
mtrys <- 1:20
nodesizes <- 1:20
results <- matrix(nrow=20, ncol=20)

for (i in 1:20) {
  for (j in 1:20) {
    set.seed(1)
    temp_model <- randomForest(`Home_Won` ~ ., data=df, ntree=3000, mtry=mtrys[i], nodesize=nodesizes[j])
    results[i,j] <- temp_model$err.rate[ntree,1]
  }
}
```
