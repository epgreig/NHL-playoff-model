---
title: "dimension_reduction"
author: "Ethan Greig"
date: "1/20/2019"
output: html_document
---

```{r}
library(knitr)
source(purl('import_and_generate_series.Rmd', output = tempfile()))
# Note that only data from 2008-2017 is imported here. 2018 data is kept as a holdout set
```

# Tune LASSO's Learning Rate Hyperparameter
```{r}
library(glmnet)
# Use elastic net (mixture of L1 and L2 regularization) for feature selection. Use mixing parameter alpha=0.5 and vary the penalty coefficient lambda, while monitoring which features have non-zero coefficients in each iteration.

# base case: alpha=1 (pure L1 error)
temp_model <- glmnet(Home_Won ~ ., data=df, alpha=0.5, family='binomial', lambda=1)
features_non_zero <- ceiling(abs(coef(temp_model))/100)

lambdas <- seq(0,0.5,by=0.0001)

for (i in 1:length(lambdas)) {
  temp_model <- glmnet(Home_Won ~ ., data=df, alpha=0.5, family='binomial', lambda=lambdas[i])
  features_non_zero <- features_non_zero + ceiling(abs(coef(temp_model))/100)
}

m <- matrix(features_non_zero[2:27])
rownames(m) <- rownames(features_non_zero)[2:27]
hist <- m[order(-m), , drop = FALSE]
plot(hist, type='h')
text(hist, rownames(hist), srt=90, pos=3, offset=5)
```

